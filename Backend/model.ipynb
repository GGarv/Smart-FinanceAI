{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Krack Hack**\n",
    "## **Theme:**\n",
    "1) AI for Sustainable development goals\n",
    "2) Intelligent Financial Advisor\n",
    "\n",
    "### **Problem Statement:**\n",
    "Many individuals lack access to personalized financial advice and struggle to perform cash flow analysis. Moreover, there is a need for leveraging AI to address sustainable development goals (SDGs) such as financial empowerment  enabling individuals to make sound financial decisions and plans.\n",
    "\n",
    "### **Solution (Building application for Financial advisory using GPT-3.5 Turbo Model, FAISS, LANGCHAIN, RAG Model, Next.JS with Voice Features)**\n",
    "Develop an intelligent financial advisor platform that integrates artificial intelligence  to offer personalized financial advice and cash flow analysis to users. This platform will assist users in making informed decisions regarding investments and financial goals, thereby promoting financial empowerment.. This solution aligns with SDGs by addressing the need for financial empowerment to  promote sustainable development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Information**\n",
    "   - The data consists of 9 books\n",
    "   1) TRACTION : GET A GRIP ON YOUR BUSINESS - GINO\tWICKMAN\n",
    "   2) Rich Dad Poor dad\n",
    "   3) The Intelligent Investor - BENJAMIN GRAHAM\n",
    "   4) The Millionaire Next Door ( Thomas J. Stanley & William D. Danko, 1998)\n",
    "   5) The Total Money Makeover - Dave Ramsey\n",
    "   6) The-Little-Book-of-Common-Sense-Investing\n",
    "   7) The-Psychology-of-Money\n",
    "   8) Thinking-Fast-and-Slow\n",
    "   9) I Will Teach You To Be Rich - Ramit Sethi\n",
    "   \n",
    "**Loading the document and splitting text:**\n",
    "   - Loading the pdf file using PyPDFLoader and extracted text from the pdf \n",
    "   - Splitting the text into smaller chunks using langchain.text_splitter\n",
    "\n",
    "**Text Embeddings:**\n",
    "   - Text embeddings are generated using the `HuggingFaceEmbeddings` class from `langchain_community.embeddings`.\n",
    "   - The model used for embedding is 'sentence-transformers/all-MiniLM-L6-v2', and it is configured to run on the CPU.\n",
    "\n",
    "**Converting to vectors and saving it**\n",
    "   - Converted text to vector using FAISS class from langchain_community.vectorstores and then saving the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<-------------------------------------------------------------------------------------------------->\n",
    "#Importing the required libraries\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "#<-------------------------------------------------------------------------------------------------->\n",
    "DATA_PATH = 'data/'  #Path containing my data\n",
    "DB_FAISS_PATH = 'vectorstore/db_faiss'  #Path where we store the embeddings of the data\n",
    "#<-------------------------------------------------------------------------------------------------->\n",
    "#Function for creating embeddings of my data\n",
    "def create_vector_db():\n",
    "    #Loading the data\n",
    "    loader = DirectoryLoader(DATA_PATH,glob='*.pdf',loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "\n",
    "    #Splitting the data\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "\n",
    "    #Converting to embeddings using sentence transformer model \n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "                                       model_kwargs={'device': 'cpu'})\n",
    "    db = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "    #Saving the model\n",
    "    db.save_local(DB_FAISS_PATH)\n",
    "\n",
    "    #Returns the database\n",
    "    return db\n",
    "#<-------------------------------------------------------------------------------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating a RAG Using LangChain and FAISS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Calling the function created above which converts the text data into embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #<-------------------------------------------------------------------------------------------------->\n",
    "# #Storing the embeddings into db1\n",
    "# db1=create_vector_db()\n",
    "# #<-------------------------------------------------------------------------------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Loading the embeddings created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #<-------------------------------------------------------------------------------------------------->\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "                                       model_kwargs={'device': 'cpu'})\n",
    "db1 = FAISS.load_local(DB_FAISS_PATH,embeddings)\n",
    "# #<-------------------------------------------------------------------------------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It creates a retriever using a vector store (`db1`). The retriever is configured for similarity search, enabling the retrieval of documents similar to a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<-------------------------------------------------------------------------------------------------->\n",
    "#It checks similar content\n",
    "retriever = db1.as_retriever(\n",
    "   search_type=\"similarity\",\n",
    "   search_kwargs={'k': 100}\n",
    ")\n",
    "#<-------------------------------------------------------------------------------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking our vector database and see if it can retrieve similar chunks of content giving some prompt\n",
    "- It is basically fetching the output of the prompt from the vector database only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buy . Investing is not buying. It’ s more a case of knowing.\n",
      "3. Organize smart people.\n",
      "Intelligent people are those who work with or hire a person who is\n",
      "more intelligent than they are. When you need advice, make sure\n",
      "you choose your advisor wisely .\n",
      "There is a lot to learn, but the rewards can be astronomical. If you do\n",
      "not want to learn those skills, then being a type-one investor is highly\n",
      "recommended. It is what you know that is your greatest wealth. It is what\n"
     ]
    }
   ],
   "source": [
    "#<-------------------------------------------------------------------------------------------------->\n",
    "#Query to ask from the database\n",
    "query = \"I want to start investing, give me some tips\"\n",
    "\n",
    "#Fetching it from above\n",
    "docs = db1.similarity_search(query)\n",
    "print(docs[0].page_content)\n",
    "#<-------------------------------------------------------------------------------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We return a lot of text here and it's not that clear what we need or what is relevant. Fortunately, our LLM will be able to parse this information much faster than us. All we need is to connect the output from our `vectorstore` to our `chat` chatbot. To do that we can use the same logic as we used earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #<-------------------------------------------------------------------------------------------------->\n",
    "def augment_prompt(query: str):\n",
    "    # get top 3 results from knowledge base\n",
    "    results = db1.similarity_search(query, k=10)\n",
    "    # get the text from the results\n",
    "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
    "    # feed into an augmented prompt\n",
    "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "    Contexts:\n",
    "    {source_knowledge}\n",
    "\n",
    "    Query: {query}\"\"\"\n",
    "    return augmented_prompt\n",
    "# #<-------------------------------------------------------------------------------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this we produce an augmented prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the contexts below, answer the query.\n",
      "\n",
      "    Contexts:\n",
      "    buy . Investing is not buying. It’ s more a case of knowing.\n",
      "3. Organize smart people.\n",
      "Intelligent people are those who work with or hire a person who is\n",
      "more intelligent than they are. When you need advice, make sure\n",
      "you choose your advisor wisely .\n",
      "There is a lot to learn, but the rewards can be astronomical. If you do\n",
      "not want to learn those skills, then being a type-one investor is highly\n",
      "recommended. It is what you know that is your greatest wealth. It is what\n",
      "now\tyou\tunderstand\tconcepts,\tlike\tautomation\tand\tIRAs,\tthat\twould\thave\n",
      "seemed\tforeign\tjust\ta\tfew\tweeks\tago.\tThe\tbest\tthing\tyou\tcan\tdo\tis\tbe\ta\tgreat\n",
      "example\tto\tothers\tand,\tif\tthey\twant\tyour\tadvice,\tshare\tthis\tbook\twith\tthem.\n",
      "Ignore\tthe\tnoise.\tRemember,\tinvesting\tshouldn’t\tbe\tdramatic\tor\teven\tfun\n",
      "—it\tshould\tbe\tmethodical,\tcalm,\tand\tas\tfun\tas\twatching\tgrass\tgrow.\t(What\n",
      "you\tcan\t\n",
      "do\n",
      "\twith\tyour\tinvestments—and\tyour\tRich\tLife—\n",
      "that’s\n",
      "\tfun!)\n",
      "good investors.\n",
      "Education and wisdom about money are important. Start early . Buy a\n",
      "book. Go to a seminar . Practice. Start small. I turned $5,000 cash into a one-\n",
      "million-dollar asset producing $5,000 a month cash flow in less than six\n",
      "years. But I started learning as a kid. I encourage you to learn, because it’ s\n",
      "not that hard. In fact, it’ s pretty easy once you get the hang of it.\n",
      "I think I have made my message clear . It’ s what is in your head that\n",
      "that\tkeep\tpeople\tbelieving\tthat\tactive\tinvestment\tis\tworth\tit—then\twe\tcan\n",
      "start\tinvesting.\n",
      "Now\tthat\tyou’ve\tread\tabout\tthe\tmyth\tof\texpertise,\tit’s\ttime\tto\tsee\texactly\n",
      "how\tyou\tcan\tinvest\tyour\town\tmoney\tto\tget\tbetter\treturns\tfor\tlower\tcost.\tIn\n",
      "the\tnext\tchapter,\tI’ll\tteach\tyou\teverything\tyou\tneed\tto\tknow\tabout\tinvesting,\n",
      "and\twe’ll\tcover\tall\tthe\ttechnical\taspects\tof\tselecting\tand\tautomating\tyour\n",
      "investments.\tLet’s\tdo\tthis.\n",
      "P.S.—If\tyou’re\tlooking\tfor\tAction\tSteps,\tkeep\treading.\tThis\tchapter\tis\n",
      "So for those who want a to-do list on how to get started, I will share\n",
      "with you some of the things I do, in abbreviated form.\n",
      "• Stop doing what you’r e doing . In other words, take a break and\n",
      "assess what is working and what is not working. The definition of\n",
      "insanity is doing the same thing over and over and expecting a\n",
      "dif ferent result. Stop doing what is not working, and look for\n",
      "something new .\n",
      "• Look for new ideas . For new investing ideas, I go to bookstores and\n",
      "I am often asked, “How do I start?”\n",
      "In the final chapter of this book, I of fer 10 steps that I followed on the\n",
      "road to my financial freedom. But always remember to have fun. When you\n",
      "learn the rules and the vocabulary of investing and begin to build your asset\n",
      "column, I think you’ll find that it’ s as fun a game as you’ve ever played.\n",
      "Sometimes you win and sometimes you learn. But have fun. Most people\n",
      "never win because they’re more afraid of losing. That is why I found school\n",
      "Most\tpeople\tdon’t\tknow\tthe\tfirst\tthing\tabout\thow\tto\tpick\tinvestments—\n",
      "but\tnow\tyou\twill!\tAh,\tthe\tpromised\tland\tis\tsweet.\n",
      "I\tused\tthe\tadvice\tfrom\n",
      "IWT\tto\tset\tup\tmy\n",
      "Schwab\tIRA,\tpersonal\n",
      "investment\taccount,\n",
      "and\tchecking\taccount\n",
      "prior\tto\tstarting\tmy\n",
      "first\tjob\twhen\tI\twas\n",
      "twenty-four.\tI’m\tnow\n",
      "thirty\tand\thave\tover\n",
      "$300,000\t saved\n",
      "between\tmy\tpersonal\n",
      "investment\taccount,\n",
      "401(k),\tand\tIRA.\n",
      "—SMIT\tSHAH,\t30\n",
      "A\tBetter\tWay\tto\tInvest:\tAutomatic\n",
      "Investing\n",
      "L\n",
      "beginning; the fun gets bigger and better as we get higher in the steps.\n",
      "Investing, of course, begins at Baby Step Four (Invest 15 Percent of Your\n",
      "Income in Retirement). You are not getting the full use and enjoyment of your\n",
      "money unless you do all three.\n",
      " \n",
      "Someone who never has fun with money misses the point. Someone who\n",
      "never invests money will never have any. Someone who never gives is a\n",
      "monkey with his hand in a bottle. Do some of each, and if you are married, let\n",
      "and\tperhaps\teven\tother\tinvestment\taccounts.)\tBy\tthe\tend\tof\tthis\tchapter,\n",
      "you’ll\tknow\texactly\twhat\tto\tinvest\tin—and\twhy.\tAnd\tyou’ll\tdo\tit\twith\n",
      "minimal\thuman\tinvolvement,\tincurring\tminimal\texpense.\n",
      "My\tgoal\tis\tto\thelp\tyou\tpick\tthe\tsimplest\tinvestment\tto\tget\tstarted—and\tto\n",
      "make\tyour\tportfolio\teasy\tto\tmaintain.\tBy\tdoing\tjust\tthose\ttwo\tthings,\tyou’ll\n",
      "be\ton\tthe\tway\tto\tgetting\trich.\tYou’ll\trealize\tthat\tlots\tof\tpeople\twith\thigh\n",
      "salaries\thave\tno\tsavings\tor\tinvestments.\tYou’ll\tstart\tnoticing\tthe\texcuses\n",
      "—ROSS\tWHITE,\t30\n",
      "The\tLadder\tof\tPersonal\tFinance\n",
      "T\n",
      "hese\tare\tthe\tsix\tsystematic\tsteps\tyou\tshould\ttake\tto\tinvest.\tEach\tstep\tbuilds\n",
      "on\tthe\tprevious\tone,\tso\twhen\tyou\tfinish\tthe\tfirst,\tgo\ton\tto\tthe\tsecond.\tIf\tyou\n",
      "can’t\tget\tto\tnumber\t6,\tdon’t\tworry—do\tyour\tbest\tfor\tnow.\tIn\tChapter\t5,\tI’ll\n",
      "show\tyou\thow\tto\tmake\tthis\tautomatic\tso\tyour\tsystem\tcan\trun\titself\twith\tjust\ta\n",
      "few\thours\tof\twork\tper\tyear—but\tremember,\topening\tthese\taccounts\tand\n",
      "getting\tstarted\tis\tthe\tmost\timportant\tstep.\n",
      "Rung\t1:\n",
      "\n",
      "    Query: I want to start investing, give me some tips\n"
     ]
    }
   ],
   "source": [
    "# #<-------------------------------------------------------------------------------------------------->\n",
    "query = \"I want to start investing, give me some tips\"\n",
    "print(augment_prompt(query))\n",
    "# #<-------------------------------------------------------------------------------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Building LLM Chain for Question-Answering and Integrating Retreival Augmented generation (RAG)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are using OpenAI API to access the GPT-3.5 Turbo model\n",
    "\n",
    "- The prompt_template variable is a string that contains a template for the prompt that will be given to the model. This template includes an instruction section, which provides context for the question, and a question section, which contains the actual question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #<-------------------------------------------------------------------------------------------------->\n",
    "#Importing Libraries\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "import openai\n",
    "# #<-------------------------------------------------------------------------------------------------->\n",
    "# Loading the GPT-3.5 Turbo model\n",
    "openai.api_key = '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'\n",
    "model_id = 'gpt-3.5-turbo'\n",
    "# #<-------------------------------------------------------------------------------------------------->\n",
    "# Generating template of prompt to give to my model\n",
    "prompt_template = \"\"\"\n",
    "### [INSTRUCTION]\n",
    "Answer the question based on your financial advisory, investment, stock, loans knowledge. Here is context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "### QUESTION:\n",
    "{question}\n",
    "\n",
    "[/INSTRUCTION]\n",
    "\"\"\"\n",
    "# #<-------------------------------------------------------------------------------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This function generate_response(prompt) generates a response using the **LLM chain** and taking context from the data which we gave in vector database which makes a **RAG Chain** \n",
    "- These functions work together to generate a prompt from a template and then use that prompt to get a response from the OpenAI GPT-3.5 model and then checking in the **vector database** for the context realted to the prompt and updating the output based on the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<-------------------------------------------------------------------------------------------------->\n",
    "# Create prompt from prompt template\n",
    "def generate_prompt(context, question):\n",
    "    prompt = prompt_template.format(context=context, question=question)\n",
    "    return prompt\n",
    "\n",
    "# #<-------------------------------------------------------------------------------------------------->\n",
    "\n",
    "# Creating LLM chain\n",
    "def generate_respons(prompt):\n",
    "    # Create a list of messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful financial advisor.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "\n",
    "    # Call the OpenAI API with the list of messages\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model_id,\n",
    "        messages=messages,\n",
    "        temperature=0.5,\n",
    "        max_tokens=2500,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "\n",
    "    # Return the text content of the response\n",
    "    return response.choices[0].message.content.strip()\n",
    "# #<-------------------------------------------------------------------------------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testing our model created on RAG chain**\n",
    "- Printing the output by the llm model by giving context to it from the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some tips to help you get started with investing:\n",
      "\n",
      "1. Educate yourself: Take the time to learn about different investment options, such as stocks, bonds, mutual funds, and real estate. Understand the risks and potential returns associated with each type of investment.\n",
      "\n",
      "2. Set clear financial goals: Determine why you want to invest and what you hope to achieve. This will help guide your investment decisions and keep you focused.\n",
      "\n",
      "3. Start small: Begin with a small amount of money that you are comfortable investing. This allows you to gain experience and confidence without risking too much.\n",
      "\n",
      "4. Diversify your portfolio: Spread your investments across different asset classes and industries to reduce risk. Diversification helps protect your portfolio from the impact of any single investment performing poorly.\n",
      "\n",
      "5. Consider your risk tolerance: Understand how much risk you are willing to take on. Investments with higher potential returns often come with higher risks. Make sure your investment choices align with your risk tolerance.\n",
      "\n",
      "6. Stay focused on the long term: Investing is a long-term endeavor. Avoid making impulsive decisions based on short-term market fluctuations. Stick to your investment plan and avoid trying to time the market.\n",
      "\n",
      "7. Seek professional advice if needed: If you are unsure about how to begin or need guidance, consider consulting with a financial advisor. They can help assess your financial situation, goals, and risk tolerance, and provide personalized investment advice.\n",
      "\n",
      "Remember, investing involves risks, and it's important to do your own research and make informed decisions based on your individual circumstances.\n"
     ]
    }
   ],
   "source": [
    "#<-------------------------------------------------------------------------------------------------->\n",
    "# Query to be asked\n",
    "query = \"I want to start investing, give me some tips\"\n",
    "\n",
    "# Invoking query in pipeline\n",
    "context = augment_prompt(query)\n",
    "prompt = generate_prompt(context, query)\n",
    "response = generate_respons(prompt)\n",
    "# Storing output text\n",
    "output = response\n",
    "print(output)\n",
    "# #<-------------------------------------------------------------------------------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Voice-Recognition**\n",
    "- Adding voice functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #<-------------------------------------------------------------------------------------------------->\n",
    "# #Importing the libraries\n",
    "# import speech_recognition as sr\n",
    "# import pyttsx3\n",
    "# # #<-------------------------------------------------------------------------------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Building all the required functions for handling voice features\n",
    "1) Convert voice to text\n",
    "2) text to speech\n",
    "3) Speech to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #<-------------------------------------------------------------------------------------------------->\n",
    "# recognizer = sr.Recognizer()\n",
    "# def capture_voice_input():\n",
    "#     with sr.Microphone() as source:\n",
    "#         print(\"Listening...\")\n",
    "#         audio = recognizer.listen(source)\n",
    "#     return audio\n",
    "# # #<-------------------------------------------------------------------------------------------------->\n",
    "# def convert_voice_to_text(audio):\n",
    "#     try:\n",
    "#         text = recognizer.recognize_google(audio)\n",
    "#         print(\"You said: \" + text)\n",
    "#     except sr.UnknownValueError:\n",
    "#         text = \"\"\n",
    "#         print(\"Sorry, I didn't understand that.\")\n",
    "#     except sr.RequestError as e:\n",
    "#         text = \"\"\n",
    "#         print(\"Error; {0}\".format(e))\n",
    "#     return text\n",
    "# # #<-------------------------------------------------------------------------------------------------->\n",
    "# def text_to_speech(text):\n",
    "#     engine = pyttsx3.init()\n",
    "#     engine.say(text)\n",
    "#     engine.runAndWait()\n",
    "# # #<-------------------------------------------------------------------------------------------------->\n",
    "# def speech_to_text():\n",
    "#     recognizer = sr.Recognizer()\n",
    "#     with sr.Microphone() as source:\n",
    "#         print(\"Say something:\")\n",
    "#         audio = recognizer.listen(source)\n",
    "\n",
    "#     try:\n",
    "#         print(\"You said: \" + recognizer.recognize_google(audio))\n",
    "#     except sr.UnknownValueError:\n",
    "#         print(\"Could not understand audio\")\n",
    "#     except sr.RequestError as e:\n",
    "#         print(\"Could not request results; {0}\".format(e))\n",
    "\n",
    "# # #<-------------------------------------------------------------------------------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Summarizing the generated response by our model**\n",
    "- Using facebook bart large cnn model for this task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #<-------------------------------------------------------------------------------------------------->\n",
    "# #Importing libraries for text summarization\n",
    "# from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "# model_name = \"facebook/bart-large-cnn\"\n",
    "# tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "# model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "# # #<-------------------------------------------------------------------------------------------------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #<-------------------------------------------------------------------------------------------------->\n",
    "# def summarze_output(output):\n",
    "#     input_text =output\n",
    "#     inputs = tokenizer.encode(\"summarize: \" + input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "#     summary_ids = model.generate(inputs, max_length=100, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "#     summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "#     return summary\n",
    "# # #<-------------------------------------------------------------------------------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Callling the above functions and integrating them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some tips to help you get started with investing:\n",
      "\n",
      "1. Educate yourself: Take the time to learn about different investment options, such as stocks, bonds, mutual funds, and real estate. Understand the risks and potential returns associated with each.\n",
      "\n",
      "2. Set clear financial goals: Determine what you want to achieve with your investments. Are you saving for retirement, a down payment on a house, or a child's education? Setting specific goals will help you make better investment decisions.\n",
      "\n",
      "3. Start small: Begin with a small amount of money that you can afford to invest. This will allow you to gain experience and learn from any mistakes without risking a significant portion of your savings.\n",
      "\n",
      "4. Diversify your portfolio: Spread your investments across different asset classes and industries. Diversification helps reduce risk by minimizing the impact of any single investment performing poorly.\n",
      "\n",
      "5. Consider your risk tolerance: Understand your comfort level with risk and invest accordingly. Generally, higher-risk investments offer the potential for higher returns, but also come with increased volatility.\n",
      "\n",
      "6. Invest for the long term: Investing is a long-term game. Avoid making impulsive decisions based on short-term market fluctuations. Stay focused on your goals and stick to your investment strategy.\n",
      "\n",
      "7. Seek professional advice: Consider consulting with a financial advisor who can provide personalized guidance based on your specific financial situation and goals. They can help you create a tailored investment plan and provide ongoing support.\n",
      "\n",
      "Remember, investing involves risks, and it's important to do your due diligence and make informed decisions. Start small, be patient, and continuously educate yourself to become a more knowledgeable investor over time.\n"
     ]
    }
   ],
   "source": [
    "# #<-------------------------------------------------------------------------------------------------->\n",
    "# audio = capture_voice_input()\n",
    "# query = convert_voice_to_text(audio)\n",
    "context = augment_prompt(query)\n",
    "prompt = generate_prompt(context, query)\n",
    "response = generate_respons(prompt)\n",
    "# #<-------------------------------------------------------------------------------------------------->\n",
    "out = response\n",
    "print(out)\n",
    "# #<-------------------------------------------------------------------------------------------------->\n",
    "# print(summarze_output(out))\n",
    "# #<-------------------------------------------------------------------------------------------------->      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Query\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "app = FastAPI()\n",
    "origins = [\n",
    "    \"http://localhost:3000\",  # Add other allowed origins as needed\n",
    "]\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=origins,\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "@app.get(\"/generate_response/\")\n",
    "async def generate_response(input_data: str = Query(..., title=\"input_data\", description=\"Enter your prompt here\")):\n",
    "    context = augment_prompt(input_data)\n",
    "    prompt = generate_prompt(context, input_data)\n",
    "    response = generate_respons(prompt)\n",
    "    # summarze_output(response)\n",
    "    return {\"response\": response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [10028]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:55509 - \"GET /generate_response?input_data= HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     127.0.0.1:55509 - \"GET /generate_response/?input_data= HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55644 - \"GET /generate_response?input_data= HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     127.0.0.1:55644 - \"GET /generate_response/?input_data= HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55726 - \"GET /generate_response?input_data= HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     127.0.0.1:55726 - \"GET /generate_response/?input_data= HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55759 - \"GET /generate_response?input_data= HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     127.0.0.1:55759 - \"GET /generate_response/?input_data= HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55930 - \"GET /generate_response?input_data=Give%20me%20some%20bussiness%20ideas HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     127.0.0.1:55930 - \"GET /generate_response/?input_data=Give%20me%20some%20bussiness%20ideas HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56058 - \"GET /generate_response?input_data=tell%20me%20some%20points%20which%20is%20should%20follow%20to%20build%20my%20startup. HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     127.0.0.1:56058 - \"GET /generate_response/?input_data=tell%20me%20some%20points%20which%20is%20should%20follow%20to%20build%20my%20startup. HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56059 - \"GET /generate_response?input_data=tell%20me%20some%20points%20which%20is%20should%20follow%20to%20build%20my%20startup. HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     127.0.0.1:56059 - \"GET /generate_response?input_data=tell%20me%20some%20points%20which%20is%20should%20follow%20to%20build%20my%20startup. HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     127.0.0.1:56059 - \"GET /generate_response?input_data=tell%20me%20some%20points%20which%20is%20should%20follow%20to%20build%20my%20startup. HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     127.0.0.1:56058 - \"GET /generate_response/?input_data=tell%20me%20some%20points%20which%20is%20should%20follow%20to%20build%20my%20startup. HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56058 - \"GET /generate_response/?input_data=tell%20me%20some%20points%20which%20is%20should%20follow%20to%20build%20my%20startup. HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56066 - \"GET /generate_response/?input_data=tell%20me%20some%20points%20which%20is%20should%20follow%20to%20build%20my%20startup. HTTP/1.1\" 500 Internal Server Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py\", line 753, in _interpret_response_line\n",
      "    data = json.loads(rbody)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 404, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 84, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\applications.py\", line 123, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\middleware\\cors.py\", line 91, in __call__\n",
      "    await self.simple_response(scope, receive, send, request_headers=headers)\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\middleware\\cors.py\", line 146, in simple_response\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 62, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\routing.py\", line 762, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\routing.py\", line 782, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\routing.py\", line 297, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\routing.py\", line 77, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\routing.py\", line 72, in app\n",
      "    response = await func(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastapi\\routing.py\", line 299, in app\n",
      "    raise e\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastapi\\routing.py\", line 294, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastapi\\routing.py\", line 191, in run_endpoint_function\n",
      "    return await dependant.call(**values)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Garv Gupta\\AppData\\Local\\Temp\\ipykernel_10028\\2376050932.py\", line 20, in generate_response\n",
      "    response = generate_respons(prompt)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Garv Gupta\\AppData\\Local\\Temp\\ipykernel_10028\\462468668.py\", line 18, in generate_respons\n",
      "    response = openai.ChatCompletion.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\Garv Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py\", line 755, in _interpret_response_line\n",
      "    raise error.APIError(\n",
      "openai.error.APIError: HTTP code 502 from API (<html>\n",
      "<head><title>502 Bad Gateway</title></head>\n",
      "<body>\n",
      "<center><h1>502 Bad Gateway</h1></center>\n",
      "<hr><center>cloudflare</center>\n",
      "</body>\n",
      "</html>\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:56085 - \"GET /generate_response?input_data=tell%20me%20some%20startup%20ideas HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     127.0.0.1:56085 - \"GET /generate_response/?input_data=tell%20me%20some%20startup%20ideas HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56152 - \"GET /generate_response?input_data=give%20some%20points%20to%20build%20my%20startup HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     127.0.0.1:56152 - \"GET /generate_response/?input_data=give%20some%20points%20to%20build%20my%20startup HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56161 - \"GET /generate_response?input_data=give%20some%20points%20to%20build%20my%20startup HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     127.0.0.1:56161 - \"GET /generate_response/?input_data=give%20some%20points%20to%20build%20my%20startup HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56220 - \"GET /generate_response?input_data=how%20to%20start%20my%20startup. HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     127.0.0.1:56220 - \"GET /generate_response/?input_data=how%20to%20start%20my%20startup. HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56780 - \"GET /generate_response?input_data=give%20me%20some%20tips%20to%20start%20a%20successful%20business HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     127.0.0.1:56780 - \"GET /generate_response/?input_data=give%20me%20some%20tips%20to%20start%20a%20successful%20business HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56812 - \"GET /generate_response?input_data=give%20me%20some%20tips%20to%20start%20a%20startup HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     127.0.0.1:56812 - \"GET /generate_response/?input_data=give%20me%20some%20tips%20to%20start%20a%20startup HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56850 - \"GET /generate_response?input_data=i%20am%20having%20100000%20rs%20as%20savings%20tell%20me%20how%20to%20invest%20them HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     127.0.0.1:56850 - \"GET /generate_response/?input_data=i%20am%20having%20100000%20rs%20as%20savings%20tell%20me%20how%20to%20invest%20them HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import uvicorn\n",
    "if __name__ == \"__main__\":\n",
    "    config = uvicorn.Config(app)\n",
    "    server = uvicorn.Server(config)\n",
    "    await server.serve()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
